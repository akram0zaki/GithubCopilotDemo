1
00:00:00,000 --> 00:00:03,253
I think we as a society celebrate
tech companies

2
00:00:03,253 --> 00:00:07,215
far too much versus
the impact of technology.

3
00:00:07,298 --> 00:00:10,593
think about the decades
all of us have spent saying,

4
00:00:10,802 --> 00:00:15,890
can we have one tech intervention
that makes a damn difference in education,

5
00:00:16,057 --> 00:00:21,021
we are definitely trying to build
a scaffolding for the AI age. I'm curious

6
00:00:21,021 --> 00:00:25,358
what you think the world will look like
when 90 or 95% of all code is generated by AI?

7
00:00:25,358 --> 00:00:27,360
Ultimately the human is in the loop,

8
00:00:27,360 --> 00:00:29,612
I think we overstate the autonomy here.

9
00:00:29,612 --> 00:00:33,283
Remember at Microsoft
we are not like there's one trick company.

10
00:00:33,324 --> 00:00:35,994
the hardest thing for us
is being adjusting.

11
00:00:35,994 --> 00:00:38,371
The reality is, case studies don't help.

12
00:00:38,371 --> 00:00:42,625
You have to do it yourself technology
is powerful enough to disappear.

13
00:00:42,667 --> 00:00:44,961
This is something that recently
went viral.

14
00:00:44,961 --> 00:00:48,423
you mentioned
that AGI is just some nonsensical

15
00:00:48,423 --> 00:00:53,011
benchmark hacking,
and the true value of AI is...

16
00:00:53,887 --> 00:00:54,554
All right.

17
00:00:54,554 --> 00:00:56,473
Satya, thanks so much for being here.

18
00:00:56,473 --> 00:01:00,101
So we're just minutes after
you just hopped off the stage at Build.

19
00:01:00,310 --> 00:01:03,313
Can you explain
how all these new developments

20
00:01:03,313 --> 00:01:06,691
really are coming together
to build that new agenetic web?

21
00:01:06,691 --> 00:01:09,527
Yeah. First of all, thanks so much
for being at the developer conference.

22
00:01:09,527 --> 00:01:13,281
And you know, for us,
the it's it's interesting,

23
00:01:13,281 --> 00:01:16,117
you know, when I think about this,
we're at that moment, right?

24
00:01:16,117 --> 00:01:16,451
Whatever.

25
00:01:16,451 --> 00:01:19,454
2 or 3 years into a platform shift,

26
00:01:19,454 --> 00:01:22,832
and you start talking about the platform,

27
00:01:22,832 --> 00:01:26,878
not just about the one app or the few apps
and how they got built.

28
00:01:26,878 --> 00:01:27,003
Right.

29
00:01:27,003 --> 00:01:32,342
Because you're about to sort of start
scaling, things in a much more.

30
00:01:32,634 --> 00:01:34,469
I'll call a generalized way

31
00:01:34,469 --> 00:01:37,514
where as a developer,
you can start seeing how to build it.

32
00:01:37,555 --> 00:01:38,848
I mean, one of the best things,

33
00:01:38,848 --> 00:01:41,768
that we talked about
was that Stanford demo, right?

34
00:01:41,768 --> 00:01:43,770
Stanford Medicine, think about it. Right.

35
00:01:43,770 --> 00:01:46,773
Something high stakes,
like a tumor board meeting.

36
00:01:46,940 --> 00:01:50,401
How do you use AI to have better
tumor board meetings?

37
00:01:50,693 --> 00:01:54,030
That's a real thing
that one can go to work on.

38
00:01:54,447 --> 00:01:59,702
In order to make that the case, though,
you really have to get data from pathology

39
00:01:59,702 --> 00:02:03,206
from, you know, multiple labs from PubMed

40
00:02:03,206 --> 00:02:07,043
and all getting orchestrated
by multiple agents.

41
00:02:07,043 --> 00:02:07,418
Right.

42
00:02:07,418 --> 00:02:09,838
And then have it show up where users are.

43
00:02:09,838 --> 00:02:11,464
In that case, it was teams.

44
00:02:11,464 --> 00:02:15,093
If you're a teacher who goes to a tumor
board meeting and then wants to go to a,

45
00:02:15,426 --> 00:02:18,930
you know, class as a teaching, doctor,
you want to be able to turn that

46
00:02:18,930 --> 00:02:19,597
into PowerPoints.

47
00:02:19,597 --> 00:02:23,309
And that type of orchestration
is what you want to be able to build.

48
00:02:23,309 --> 00:02:27,230
And I feel to do that,
you got to build up a real stack

49
00:02:27,397 --> 00:02:30,108
right where every layer is open.

50
00:02:30,108 --> 00:02:31,401
It composes.

51
00:02:31,401 --> 00:02:36,156
There are standards that protocols,
and I feel like they're finally there.

52
00:02:36,156 --> 00:02:39,784
And so what is exciting to me
is to have the stack from sort of,

53
00:02:40,118 --> 00:02:44,789
Microsoft 365 Copilot to Foundry, all compose,

54
00:02:45,123 --> 00:02:50,003
with some of these things like NL web
and MCP to create this agentic web.

55
00:02:50,253 --> 00:02:53,256
In some sense, I feel like
even the original ethos of the web,

56
00:02:53,381 --> 00:02:56,384
maybe we can rediscover
which is the true openness.

57
00:02:56,426 --> 00:02:56,676
Yeah.

58
00:02:56,676 --> 00:03:00,722
And it sort of seems like Microsoft's
trying to build this all in one UI,

59
00:03:00,722 --> 00:03:04,350
where you can manage
fleets of agents on one spot.

60
00:03:04,434 --> 00:03:06,644
Is the goal
a world where every knowledge worker

61
00:03:06,644 --> 00:03:10,064
effectively becomes this agent manager
instead of just a knowledge worker?

62
00:03:10,106 --> 00:03:12,734
Yeah, it's it's a metaphor.
I think it that makes sense, right?

63
00:03:12,734 --> 00:03:17,780
When we say we are definitely trying to
build a scaffolding for the AI age, right?

64
00:03:17,780 --> 00:03:20,450
Just like, say, back in the day,
we built teams, right?

65
00:03:20,450 --> 00:03:21,117
You remember?

66
00:03:21,117 --> 00:03:23,077
Or even back in the day.

67
00:03:23,077 --> 00:03:25,788
We built outlook
right before outlook came together.

68
00:03:25,788 --> 00:03:29,209
Calendaring was a separate
app, contacts was a separate app

69
00:03:29,209 --> 00:03:30,501
and email was a separate app.

70
00:03:30,501 --> 00:03:33,004
And so then we said, oh,
maybe we should build it all together.

71
00:03:33,004 --> 00:03:34,088
And outlook was born.

72
00:03:34,088 --> 00:03:38,218
And then teams or meetings was somewhere
else, channels or somewhere else.

73
00:03:38,218 --> 00:03:39,594
And then chat was somewhere else.

74
00:03:39,594 --> 00:03:41,095
And we said, hey,
let's bring that together.

75
00:03:41,095 --> 00:03:46,226
So some, you know, I mean always there's
going to be a need for a new scaffolding.

76
00:03:46,226 --> 00:03:48,144
And in our case, with what I describe

77
00:03:48,144 --> 00:03:52,065
as a UI for AI is you say, well,
let's bring chat, let's even bring search.

78
00:03:52,065 --> 00:03:52,690
And then

79
00:03:52,690 --> 00:03:56,986
our agents and things like notebooks
and so on, all together in one interface.

80
00:03:56,986 --> 00:03:58,738
And that's what we're doing with the M365

81
00:03:58,738 --> 00:04:02,033
Copilot and teams is essentially
the multiplayer version of it.

82
00:04:02,492 --> 00:04:05,703
But it's not the only I'll call it
UI for AI.

83
00:04:05,703 --> 00:04:09,624
There will be many other places
and many other developers will build them.

84
00:04:09,624 --> 00:04:09,832
Right.

85
00:04:09,832 --> 00:04:13,711
You could say the UI for AI for
developers is get up.

86
00:04:14,128 --> 00:04:17,632
UI for AI for some scientist will be,
you know,

87
00:04:17,632 --> 00:04:20,551
what we talked about in our discovery
or some third party application.

88
00:04:20,551 --> 00:04:23,346
So I think there's going to be
a lot more richness on the UI layer

89
00:04:23,346 --> 00:04:25,223
where people will build
different modalities

90
00:04:25,223 --> 00:04:27,850
for different workflows
and different needs.

91
00:04:27,850 --> 00:04:29,102
But the interesting thing

92
00:04:29,102 --> 00:04:33,690
is the underlying capability, right
where you have, hey, you have data,

93
00:04:33,690 --> 00:04:37,819
you have multiple models,
you have these agent orchestration layers,

94
00:04:38,152 --> 00:04:42,073
you have these reasoning models
now that are capable of taking intents

95
00:04:42,073 --> 00:04:45,285
and decomposing it into multiple calls
to multiple models.

96
00:04:45,285 --> 00:04:46,869
That's I think, the exciting thing.

97
00:04:46,869 --> 00:04:48,079
You're the world of knowledge.

98
00:04:48,079 --> 00:04:51,833
Work is just changing so fast
and surely with

99
00:04:51,833 --> 00:04:55,003
any tech revolution
there will be some job displacement.

100
00:04:55,003 --> 00:04:58,131
What advice
would you give to knowledge workers.

101
00:04:58,423 --> 00:04:59,340
So that they effectively

102
00:04:59,340 --> 00:05:02,176
become these agent managers
instead of agent replacement?

103
00:05:02,176 --> 00:05:03,803
Yeah,
I think it's a good way to phrase it,

104
00:05:03,803 --> 00:05:07,181
because I think it's sort
of always helpful for us to separate out,

105
00:05:07,348 --> 00:05:10,351
the knowledge work
go from the knowledge work of today.

106
00:05:10,518 --> 00:05:13,813
Because if you think about it, right,
if you're an alien intelligence had come

107
00:05:13,813 --> 00:05:17,942
to, and seen the world,
you know, at, at, let's say, at work,

108
00:05:18,609 --> 00:05:23,573
even early 80s, and they said, oh, well,
there's a typist pool.

109
00:05:23,990 --> 00:05:27,160
There is a slide pool
or a slide making pool.

110
00:05:27,160 --> 00:05:28,995
And then if they came back,

111
00:05:28,995 --> 00:05:33,082
today, they'll say, oh,
wow, all of humanity is a typist pool.

112
00:05:33,082 --> 00:05:34,625
Because everyone gets up in the morning

113
00:05:34,625 --> 00:05:38,463
and with the two thumbs or,
with multiple fingers are all typing.

114
00:05:38,755 --> 00:05:40,256
But we are doing knowledge work.

115
00:05:40,256 --> 00:05:41,632
It's being abstracted. Right.

116
00:05:41,632 --> 00:05:45,636
So therefore, I think the levels of
abstraction, whether it's managing agents,

117
00:05:45,928 --> 00:05:50,224
if I look at even the simple, simple
workflow from when I joined Microsoft

118
00:05:50,224 --> 00:05:55,355
in 92 to now, if I had if, say, a
somebody had to get prepped for

119
00:05:55,396 --> 00:05:59,400
a, let's say, a customer visit, you know,
you would sort of go to the account team.

120
00:05:59,400 --> 00:06:03,279
The account team would write up a report,
the report would show up in the email

121
00:06:03,279 --> 00:06:05,573
that would get loaded into one note,
and I would read it.

122
00:06:05,573 --> 00:06:07,658
In fact, that was pretty much the sort of,

123
00:06:07,658 --> 00:06:10,453
you know,
I was preparing for most of my career.

124
00:06:10,453 --> 00:06:13,456
Those reports and then eventually,
you know, reading those reports

125
00:06:13,664 --> 00:06:17,710
a lot in the last even 45 months,
thanks to these

126
00:06:18,044 --> 00:06:21,255
things like reasoning models
like researcher, it's completely inverted.

127
00:06:21,255 --> 00:06:25,760
I just go prompt myself, hey, I'm meeting
with the CEO of XYZ Corporation.

128
00:06:26,177 --> 00:06:28,012
Pull all the stuff I need to know.

129
00:06:28,012 --> 00:06:29,222
It pulls from the web.

130
00:06:29,222 --> 00:06:32,141
It pulls from my emails, my documents.

131
00:06:32,141 --> 00:06:34,977
Most importantly my CRM system,
my supply chain system.

132
00:06:34,977 --> 00:06:38,398
Because most of these folks
are both customers and partners of ours.

133
00:06:38,398 --> 00:06:42,735
Gives me one comprehensive report
and then I share it with the accounting.

134
00:06:42,735 --> 00:06:45,530
Right. So think about it.
The workflow is inverted.

135
00:06:45,530 --> 00:06:48,741
So you could say yeah,
I as a CEO quote unquote, I'm

136
00:06:48,741 --> 00:06:52,662
doing more knowledge work
than I was doing, quite frankly.

137
00:06:52,662 --> 00:06:56,958
I am more employable today
because I feel more empowered.

138
00:06:56,958 --> 00:07:00,837
I feel that I can get to information
faster, collaborate

139
00:07:00,837 --> 00:07:02,463
with my colleagues in the company.

140
00:07:02,463 --> 00:07:06,050
So I do feel the best thing that can
happen is diffusion in this phase.

141
00:07:06,467 --> 00:07:09,679
I think any knowledge worker,
whether you're in software, whether you're

142
00:07:09,679 --> 00:07:14,016
in just horizontal knowledge
work, in finance and sales or in science,

143
00:07:14,517 --> 00:07:17,145
use the tools, change the work.

144
00:07:17,145 --> 00:07:20,314
Have you have the agency
to change your work artifacts,

145
00:07:20,398 --> 00:07:22,066
the workflow around you?

146
00:07:22,066 --> 00:07:26,028
And of course, you know, I'm clear eyed
that there is going to be displacement.

147
00:07:26,362 --> 00:07:31,159
And so therefore, the best defense against
that is skilling reskilling.

148
00:07:31,159 --> 00:07:35,538
And it starts by using tools versus,
not using them.

149
00:07:35,663 --> 00:07:38,749
And developers
arguably have seen the biggest shift

150
00:07:38,749 --> 00:07:40,751
to their workflows
with the rise of AI tools.

151
00:07:40,751 --> 00:07:45,256
And now agents and GitHub new Copilot
coding engine is just another example

152
00:07:45,256 --> 00:07:48,509
of another tool that's, you know,
effectively changing the developer work

153
00:07:48,593 --> 00:07:49,802
workflow so much.

154
00:07:49,802 --> 00:07:51,053
You've actually seen recently said

155
00:07:51,053 --> 00:07:56,184
that Microsoft is sharing
30% of all new code with AI.

156
00:07:57,435 --> 00:07:58,644
I'm curious what what

157
00:07:58,644 --> 00:08:02,857
you think the world will look like
when 90 or 95% of all code is generated?

158
00:08:02,857 --> 00:08:05,318
AI yeah, it's
a couple of different things, you know.

159
00:08:05,318 --> 00:08:09,113
One is you got to remember,
like when I look at the amount of deficit

160
00:08:09,113 --> 00:08:09,822
we have, right.

161
00:08:09,822 --> 00:08:14,785
If I sort of looked at, let's call what
people say is tech debt or it debt, right.

162
00:08:14,785 --> 00:08:16,662
Which is if you look around the world

163
00:08:16,662 --> 00:08:19,874
and say the number of projects
that are still unfinished,

164
00:08:20,208 --> 00:08:25,296
the reality is we need a lot more software
development, in order to be able

165
00:08:25,296 --> 00:08:30,384
to really reach, the goal
of being able to work down that deficit.

166
00:08:30,676 --> 00:08:32,929
So you start there. We have a problem.

167
00:08:32,929 --> 00:08:34,847
That is, we don't have all of the software

168
00:08:34,847 --> 00:08:38,726
development capability
and supply in order to meet the demand.

169
00:08:39,101 --> 00:08:43,814
Then you say in that context, that's
why the all these form factors, right.

170
00:08:43,814 --> 00:08:46,484
Even code completions super helpful.

171
00:08:46,484 --> 00:08:50,446
We always had intellisense,
but we now just have better intelligence

172
00:08:50,446 --> 00:08:52,240
that works with code completions.

173
00:08:52,240 --> 00:08:55,993
Or I can highlight a bunch of code
and have it explain it to me

174
00:08:55,993 --> 00:08:57,286
and it'll draw a diagram.

175
00:08:57,286 --> 00:09:00,456
You and yesterday I like took some code
and sort of just highlighted and said,

176
00:09:00,456 --> 00:09:03,626
just give it to me as a flowchart,
like just that simple thing I just

177
00:09:03,668 --> 00:09:06,671
because I do better with visual stuff.

178
00:09:06,671 --> 00:09:08,256
Then you know agents right.

179
00:09:08,256 --> 00:09:10,675
Where I can assign
synchronously some tasks.

180
00:09:10,675 --> 00:09:15,555
So multi file edits,
the full repo changes that I want done.

181
00:09:15,555 --> 00:09:15,846
Right.

182
00:09:15,846 --> 00:09:18,891
So that's all as an individual developer
I can stay in the flow.

183
00:09:18,891 --> 00:09:22,186
I can use these tools
then to be able to today the launch of

184
00:09:22,186 --> 00:09:25,398
the coding agent is pretty cool
because you know like as I said, like

185
00:09:25,398 --> 00:09:29,277
even for me and it's no longer sufficient
to for me to just file bugs.

186
00:09:29,485 --> 00:09:31,946
I got to get involved in
even fixing bugs, right?

187
00:09:31,946 --> 00:09:35,533
To the,
I mean, a programmer that I can work with.

188
00:09:35,575 --> 00:09:39,912
And of course, remember, you know,
ultimately the human is in the loop.

189
00:09:39,912 --> 00:09:42,290
I think we overstate the autonomy
here, right?

190
00:09:42,290 --> 00:09:47,044
Because even before it does any CI CD
thing, it comes back for a human review.

191
00:09:47,044 --> 00:09:47,962
Right.

192
00:09:47,962 --> 00:09:51,507
And it can be, you know, something that
you can even automate with another agent.

193
00:09:51,507 --> 00:09:56,846
But ultimately, there is a workflow here
where people inside of a development

194
00:09:56,846 --> 00:09:58,889
organization are going to work with

195
00:09:58,889 --> 00:10:02,768
these AI agents to essentially work down
the deficit we have.

196
00:10:02,768 --> 00:10:06,897
That's the world I sort of see, more
so than anything else.

197
00:10:07,189 --> 00:10:10,359
Copilot fine tuning was another
really interesting announcement,

198
00:10:10,651 --> 00:10:13,446
giving enterprise
the ability to unlock, you know, their,

199
00:10:13,446 --> 00:10:17,074
their own data and fine tune their own
code parts with it is a major unlock.

200
00:10:17,408 --> 00:10:21,245
I'm curious where you think these
domain specific agents will really excel,

201
00:10:21,245 --> 00:10:24,582
and is there any types of proprietary data
that will give companies

202
00:10:24,582 --> 00:10:27,168
a real advantage over
just like generic Copilot?

203
00:10:27,168 --> 00:10:29,295
Yeah, it's a it's
a super important question, right?

204
00:10:29,295 --> 00:10:35,134
I mean, in some sense, what is the form,
going forward and what is that edge?

205
00:10:35,134 --> 00:10:38,137
The knowledge edge of a form
is the real question.

206
00:10:38,137 --> 00:10:40,681
And that's why I think I'm really excited
about this. Copilot.

207
00:10:40,681 --> 00:10:44,143
Fine tuning,
because the idea is to be able to take

208
00:10:44,143 --> 00:10:48,522
what you have is a form,
which is your knowledge, your data,

209
00:10:48,522 --> 00:10:52,652
and use it to essentially tune,
the copilot system.

210
00:10:52,735 --> 00:10:54,320
But here's the interesting thing, right?

211
00:10:54,320 --> 00:10:57,531
You asked, which is
what's the sustainable advantage here?

212
00:10:57,531 --> 00:11:00,534
And the sustainable advantage
is to get a new sample

213
00:11:01,160 --> 00:11:04,997
to then use these reasoning models
with your data

214
00:11:05,164 --> 00:11:08,751
to then
be able to do RL in the real world.

215
00:11:08,751 --> 00:11:08,959
Right?

216
00:11:08,959 --> 00:11:13,673
So which is the reward function
from the market, reinforcing

217
00:11:13,673 --> 00:11:17,927
the application of your knowledge
to fine tuning the new sample.

218
00:11:17,927 --> 00:11:19,512
Right. That's the virtuous cycle.

219
00:11:19,512 --> 00:11:23,057
So the world keeps getting better
in terms of its model capability.

220
00:11:23,391 --> 00:11:25,017
Forms are about taking that.

221
00:11:25,017 --> 00:11:28,187
That's ultimately a commodity
that you bring into the firm.

222
00:11:28,604 --> 00:11:33,526
You then because of all the knowledge work
you do internally and the data you have,

223
00:11:33,734 --> 00:11:38,364
fine tune it, put out the output
into the world, get the signal.

224
00:11:38,364 --> 00:11:39,949
It could be a customer thumbs up.

225
00:11:39,949 --> 00:11:42,326
It could be marketplace thumbs up,
whatever.

226
00:11:42,326 --> 00:11:44,412
That's the reinforcement. Reward.

227
00:11:44,412 --> 00:11:45,746
And then you go back.

228
00:11:45,746 --> 00:11:49,250
And that I think, is sort of
the new theory of the form in my sort of,

229
00:11:49,291 --> 00:11:52,670
you know, sense of how one needs to go

230
00:11:52,670 --> 00:11:55,715
and you really are going
to have to perfect that loop.

231
00:11:56,090 --> 00:11:59,176
You've led Microsoft through multiple tech
transformations.

232
00:11:59,301 --> 00:12:04,098
What advice would you give to companies
trying to restructure around this

233
00:12:04,098 --> 00:12:04,890
agent era?

234
00:12:04,890 --> 00:12:08,853
you know, with in in tech companies
in particular, in Microsoft in particular,

235
00:12:08,853 --> 00:12:12,732
because remember at Microsoft
we are not like there's one trick company.

236
00:12:12,732 --> 00:12:16,485
In other words, at some level
the hardest thing for us is

237
00:12:16,527 --> 00:12:18,279
being adjusting.

238
00:12:18,279 --> 00:12:22,116
But when I came to Microsoft,
you know, at that time, it is unclear,

239
00:12:22,116 --> 00:12:25,119
like our existential competitor
was Novell.

240
00:12:25,202 --> 00:12:30,374
And so over the years, Microsoft
has had to learn in the hard way.

241
00:12:30,374 --> 00:12:33,210
Sometimes we've gotten it right,
sometimes we've gotten it wrong.

242
00:12:33,210 --> 00:12:37,006
How do I fundamentally change three things
how we work,

243
00:12:37,465 --> 00:12:40,092
what we work on, and how we go to market.

244
00:12:40,092 --> 00:12:40,551
Right.

245
00:12:40,551 --> 00:12:46,265
And that muscle of fundamentally
reinventing the production function

246
00:12:46,265 --> 00:12:49,268
simultaneously with the product
and the innovation,

247
00:12:49,560 --> 00:12:53,314
as well as the go to market
in the business model is a hard thing.

248
00:12:53,314 --> 00:12:56,400
It's a harsh thing,
because in some sense, I wish sometimes

249
00:12:56,400 --> 00:13:00,112
I worked on one product
that lasts, you know, multiple decades.

250
00:13:00,112 --> 00:13:02,031
For us, it's not been the case.

251
00:13:02,031 --> 00:13:07,161
Even something as big a hit as windows,
you know, stopped growing at some point.

252
00:13:07,161 --> 00:13:11,540
And so therefore, it means it meant that
we had to build other businesses.

253
00:13:12,249 --> 00:13:16,712
But I think ultimately it comes down
to culture and capability building.

254
00:13:16,712 --> 00:13:19,965
That allows you
to take more shots on goal.

255
00:13:20,007 --> 00:13:23,719
And that,
I think, is what one needs to do as

256
00:13:23,719 --> 00:13:27,473
any one of us faced with these shifts,
if you have a stable business.

257
00:13:27,473 --> 00:13:28,557
Fantastic.

258
00:13:28,557 --> 00:13:30,059
Then this is tailwind.

259
00:13:30,059 --> 00:13:32,978
You can you can take
and get more leverage out of it.

260
00:13:32,978 --> 00:13:35,981
If you have a business that's in decline,

261
00:13:35,981 --> 00:13:38,984
you can then use this as an opportunity
to reinvent yourself.

262
00:13:38,984 --> 00:13:43,072
but ultimately it comes down
to this culture capability and then hunt

263
00:13:43,072 --> 00:13:46,867
for new concepts that I think,
is what you need to practice.

264
00:13:46,867 --> 00:13:47,409
You can't like.

265
00:13:47,409 --> 00:13:51,539
One of the things I think a lot about is,
you be all like, I do this as well.

266
00:13:51,539 --> 00:13:54,583
We all sort of look at the,
you know, the shining company of the era.

267
00:13:55,084 --> 00:13:57,628
The reality is, case studies don't help.

268
00:13:57,628 --> 00:14:00,172
You have to do it yourself right now.

269
00:14:00,172 --> 00:14:03,634
Somebody said to me once, which is you
don't get fit by watching others

270
00:14:03,676 --> 00:14:05,928
go to the gym. You have to go to the gym.

271
00:14:05,928 --> 00:14:08,973
And that, I think, is what this change is
all about, right?

272
00:14:08,973 --> 00:14:10,891
It's not about admiring someone else.

273
00:14:12,059 --> 00:14:15,020
But it's about really doing the hard yards
yourself.

274
00:14:15,020 --> 00:14:18,107
I want to touch on upskilling
kind of from the top down.

275
00:14:18,107 --> 00:14:21,318
So from my perspective, my company,
we work with a lot of different

276
00:14:21,318 --> 00:14:25,114
enterprises, kind of consulting them
on their strategy and what we've seen

277
00:14:25,114 --> 00:14:29,159
is that there's a lack of personalization
in education.

278
00:14:29,869 --> 00:14:32,913
For example, like the tools and workflows
a marketer might use

279
00:14:32,913 --> 00:14:35,583
are different than a developer
or someone in Customer Success.

280
00:14:35,583 --> 00:14:39,545
So I'm curious
how Microsoft is kind of educating

281
00:14:39,545 --> 00:14:42,631
their employees from the top down on,
on this sort of personalized education.

282
00:14:42,631 --> 00:14:43,257
It's a great point.

283
00:14:43,257 --> 00:14:47,845
So one of the things that we're
emphasizing is getting the tools in.

284
00:14:47,845 --> 00:14:48,137
Right.

285
00:14:48,137 --> 00:14:50,472
Because if you look back
even like one of the things

286
00:14:50,472 --> 00:14:54,393
I'm heavily influenced by
is how PCs became standard issue.

287
00:14:54,393 --> 00:14:54,560
Right?

288
00:14:54,560 --> 00:14:58,063
Is it fascinating to study
even how PCs penetrated the enterprise?

289
00:14:58,188 --> 00:15:02,443
First, you know, someone in legal said,
wow, this is great to write contracts up

290
00:15:02,443 --> 00:15:06,363
because I need word,
you know, with all of its footnotes

291
00:15:06,363 --> 00:15:09,700
and what have you finance
obviously loved Excel, right?

292
00:15:09,700 --> 00:15:12,494
Because, wow,
it can help me do models and so on.

293
00:15:12,494 --> 00:15:15,581
But then it turned out
that people don't work in their silos.

294
00:15:15,581 --> 00:15:16,790
They work in teams.

295
00:15:16,790 --> 00:15:20,628
And so then at some point,
like even the way we did forecast

296
00:15:20,794 --> 00:15:24,798
back, you know, pre PC,
I you know basically faxes went around.

297
00:15:24,798 --> 00:15:26,842
Somebody did an interoffice memo.

298
00:15:26,842 --> 00:15:30,179
And then eventually, you know,
you got to a forecast where,

299
00:15:30,512 --> 00:15:32,389
you know, once the PC became
standard issue,

300
00:15:32,389 --> 00:15:35,809
you just took an Excel spreadsheet,
entered some numbers, sent an email,

301
00:15:36,018 --> 00:15:39,229
all your area leads entered numbers,
and you had a forecast.

302
00:15:39,897 --> 00:15:41,190
It changed the work.

303
00:15:41,190 --> 00:15:43,442
The work artifact in the workflow.

304
00:15:43,442 --> 00:15:46,695
And it happened
not by going to a training class.

305
00:15:46,695 --> 00:15:50,449
It actually happened by diffusion
of the general purpose tool.

306
00:15:50,449 --> 00:15:53,035
In that case, PC in an office.

307
00:15:53,035 --> 00:15:56,580
So a little bit of sort of what I'm seeing
even inside of Microsoft,

308
00:15:56,580 --> 00:16:00,751
whether it's with GitHub Copilot
or whether it's with the M365 copilot

309
00:16:00,751 --> 00:16:03,879
or anywhere else, it's
just the diffusion of the tools.

310
00:16:04,546 --> 00:16:06,966
I'll just give you,
you know, one of the best examples

311
00:16:06,966 --> 00:16:10,386
at Microsoft was I was talking
to an engineer in our networking.

312
00:16:10,386 --> 00:16:11,595
I went right.

313
00:16:11,595 --> 00:16:15,057
I mean, I was talking about, man,
the AI when is growing like crazy.

314
00:16:15,057 --> 00:16:19,645
The number of fiber operators we work with
is like some, you know, insane number.

315
00:16:19,937 --> 00:16:22,272
And by the way,
all of the DevOps on it, right.

316
00:16:22,272 --> 00:16:24,858
You know, if there's a fiber cut
somewhere, it's all a manual, right?

317
00:16:24,858 --> 00:16:27,861
Literally
it is emails and calls and so on.

318
00:16:28,070 --> 00:16:30,698
So she just said, okay,
I can't deal with this.

319
00:16:30,698 --> 00:16:33,867
I have to really automate this
because otherwise, you know,

320
00:16:33,867 --> 00:16:36,870
all of Microsoft
will be just working on DevOps of fiber.

321
00:16:37,538 --> 00:16:40,833
And so she just built an agent
and in fact, a multi-agent orchestrator.

322
00:16:41,166 --> 00:16:41,500
Right.

323
00:16:41,500 --> 00:16:44,545
And by the way, she just did this
using some of the low-code,

324
00:16:44,545 --> 00:16:46,672
no code and the foundry tools. Right.

325
00:16:46,672 --> 00:16:50,676
That ability to empower people,
with tools

326
00:16:50,676 --> 00:16:55,014
and agency to go
and look for the workflow closest to them,

327
00:16:55,514 --> 00:17:00,602
that I think is what needs to happen,
just like how we were able to use,

328
00:17:00,602 --> 00:17:01,061
you know,

329
00:17:01,061 --> 00:17:03,480
I think I always say
Excel is the greatest programing,

330
00:17:03,480 --> 00:17:06,108
most ubiquitous
programing tool on the world.

331
00:17:06,108 --> 00:17:09,528
And all of us learned how to program
in Excel, essentially.

332
00:17:09,528 --> 00:17:12,322
And that's the thing
that I think is going to happen again.

333
00:17:12,322 --> 00:17:15,701
I know we don't have much time here,
but I want to quickly touch on proactive

334
00:17:15,993 --> 00:17:16,368
agents.

335
00:17:16,368 --> 00:17:19,663
So behind the scenes,
we actually got a demo of like on device

336
00:17:19,663 --> 00:17:24,668
proactive agent working on the Copilot
plus PCs where, this agent

337
00:17:24,668 --> 00:17:30,007
essentially opened up, outlook
and summarize email without an internet.

338
00:17:30,758 --> 00:17:31,925
But that's just one example.

339
00:17:31,925 --> 00:17:35,846
Are there any examples that you have
that you're really excited for?

340
00:17:36,180 --> 00:17:36,472
Yeah.

341
00:17:36,472 --> 00:17:38,682
So I think that
if I look at the continuum, right,

342
00:17:38,682 --> 00:17:44,021
so I, I'm really looking for in some sense
I'm a big fan of this Mark Weiser quote

343
00:17:44,021 --> 00:17:47,941
about ubiquitous computing, right,
where technology is powerful

344
00:17:47,941 --> 00:17:49,568
enough to disappear. Right.

345
00:17:49,568 --> 00:17:53,072
So therefore, to some degree,
the march of natural user interface

346
00:17:53,072 --> 00:17:57,117
and so on is about doing all the things

347
00:17:57,117 --> 00:18:00,079
that I intend to be done,

348
00:18:00,287 --> 00:18:03,457
with the least amount of,
I would say friction.

349
00:18:03,457 --> 00:18:03,832
Right.

350
00:18:03,832 --> 00:18:07,002
So that's why I think
when I want, like, interpret

351
00:18:07,002 --> 00:18:10,672
my intent and plan and get it done. Right.

352
00:18:10,672 --> 00:18:13,467
So that's where I think some of these
proactive agent stuff comes in.

353
00:18:14,468 --> 00:18:15,385
And I

354
00:18:15,385 --> 00:18:15,803
want to

355
00:18:15,803 --> 00:18:19,723
be in control though, like, for example,
that's why I think the, the cool agents,

356
00:18:19,723 --> 00:18:23,060
for example, the computer use agents
have to sort of get to a point,

357
00:18:23,060 --> 00:18:26,855
one that can't be fast
and better, and more reliable.

358
00:18:26,855 --> 00:18:32,319
But the more importantly, they have to be
changed as part of some intent, of mine.

359
00:18:32,319 --> 00:18:34,446
Right.
It's not like I'm going to go give task.

360
00:18:34,446 --> 00:18:36,156
Task, task tasks.

361
00:18:36,156 --> 00:18:39,660
I'm going to have a high level intent,
and then someone's going off

362
00:18:39,660 --> 00:18:41,995
and doing a bunch of work
and I can inspect.

363
00:18:41,995 --> 00:18:45,874
So that's why I think like this GitHub,
you know, coding agent, the session log,

364
00:18:46,250 --> 00:18:46,959
it's pretty cool.

365
00:18:46,959 --> 00:18:49,628
Like I go back after having a sign.

366
00:18:49,628 --> 00:18:53,757
It's like I'm watching the session log
with all the draft commits.

367
00:18:54,133 --> 00:18:56,426
Right?
So that I think is the balance. Right.

368
00:18:56,426 --> 00:19:01,181
So in an interesting way, we talk about
the proactive agent and a session log.

369
00:19:01,473 --> 00:19:05,018
And that way
then it's sort of more transparency of it.

370
00:19:05,018 --> 00:19:08,397
And then when you invoke multiple of them
you are able

371
00:19:08,397 --> 00:19:11,400
to still track effectively
what's happening.

372
00:19:11,525 --> 00:19:12,901
One last question for you.

373
00:19:12,901 --> 00:19:15,779
This is something that recently
went viral.

374
00:19:15,779 --> 00:19:19,491
About two months ago,
you said you mentioned

375
00:19:19,491 --> 00:19:23,370
that AGI is just some nonsensical
benchmark hacking,

376
00:19:23,370 --> 00:19:27,791
and the true value of AI is global
economic growth.

377
00:19:27,833 --> 00:19:31,628
Where do you see agents
having the most value in that regard?

378
00:19:31,628 --> 00:19:34,298
First, it's a great one.
I mean, to me, take health care.

379
00:19:34,298 --> 00:19:40,470
What is it, 19-20% of our, GDP in
the United States is in health care.

380
00:19:40,470 --> 00:19:43,390
A lot of that cost the inefficiency.

381
00:19:43,390 --> 00:19:46,977
If you talk to any of our providers,
is all in the workflow, right?

382
00:19:47,436 --> 00:19:52,524
They're working so hard to provide
unbelievable care, except sort of,

383
00:19:52,566 --> 00:19:53,692
you know, and they're using

384
00:19:53,692 --> 00:19:57,154
all these digital systems,
but they're really not able to,

385
00:19:57,863 --> 00:20:00,657
tame the complexity and reduce the cost.

386
00:20:00,657 --> 00:20:03,744
And so if there is going to be one place
where I would love

387
00:20:03,744 --> 00:20:06,747
to love to see that productivity gain,

388
00:20:06,747 --> 00:20:10,167
would be like that,
you know, that multi-agent orchestrator

389
00:20:10,167 --> 00:20:14,254
for health care that we just launched,
used by Stanford become ubiquitous.

390
00:20:14,254 --> 00:20:18,050
And there are stories
that people are saying, oh wow, this is

391
00:20:18,050 --> 00:20:22,095
been the biggest thing that, you know,
every provider is able to provide

392
00:20:22,095 --> 00:20:23,972
better health care at lower cost. Right?

393
00:20:23,972 --> 00:20:27,226
So something like that has to happen
because my only comment

394
00:20:27,226 --> 00:20:31,772
there was not about any sort of shot
on any great AI research.

395
00:20:31,772 --> 00:20:36,610
It is more,
I think we as a society to celebrate

396
00:20:36,610 --> 00:20:41,490
tech companies far too much versus
the impact of technology.

397
00:20:41,531 --> 00:20:45,410
Quite honestly,
if there was a more balanced way to talk

398
00:20:45,410 --> 00:20:49,790
about sort of not the tech industry,
but the use of technology, right.

399
00:20:49,790 --> 00:20:52,542
That's why even the, you know, copilot
being an end to end,

400
00:20:52,542 --> 00:20:54,503
think about the decades

401
00:20:54,503 --> 00:20:58,382
all of us have spent saying,
give me a one tech intervention

402
00:20:58,590 --> 00:21:02,219
that makes a damn difference in education,
right?

403
00:21:02,427 --> 00:21:05,555
Finally,
you have real statistical evidence,

404
00:21:05,555 --> 00:21:08,141
thanks to that world Bank study in Nigeria
that,

405
00:21:08,141 --> 00:21:11,103
you know, you give people copilot their
or any other agent.

406
00:21:11,103 --> 00:21:13,563
It doesn't matter. Something changes.

407
00:21:13,563 --> 00:21:15,190
That's the story to me, right?

408
00:21:15,190 --> 00:21:17,067
That's why I joined the tech industry.

409
00:21:17,067 --> 00:21:18,652
I mean, there is a very different time.

410
00:21:18,652 --> 00:21:22,447
And suddenly it became like, you know,
the place we were celebrating ourselves.

411
00:21:22,447 --> 00:21:23,699
And I just hate it.

412
00:21:23,699 --> 00:21:28,495
I just want to get to a place
where we are talking about the technology

413
00:21:28,495 --> 00:21:31,498
being used
and when the rest of the industry across

414
00:21:31,498 --> 00:21:34,835
the globe is being celebrated
because they use technology

415
00:21:34,835 --> 00:21:37,838
to do something magical for all of us,
that would be the day.

416
00:21:37,879 --> 00:21:39,965
Okay, well,
I think that's all the time we have.

417
00:21:39,965 --> 00:21:42,801
Thank you so much again for doing this
and congrats on the great keynote.

418
00:21:42,801 --> 00:21:45,178
thank you so much. It's
such a pleasure. Great. Thank you.